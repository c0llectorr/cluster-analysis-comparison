{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b06edb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Comprehensive Clustering Analysis: K-Means vs Hierarchical Clustering\n",
    "Dataset Comparison: Iris and Mall Customers\n",
    "\n",
    "Author: Data Science Team\n",
    "Date: November 2025\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# PART 1: IMPORTS AND SETUP\n",
    "# ============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.stats import zscore\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"âœ“ All libraries imported successfully!\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 2: DATASET LOADING\n",
    "# ============================================================================\n",
    "\n",
    "# Dataset 1: Iris\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris_df['species'] = iris.target\n",
    "iris_df['species_name'] = iris_df['species'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"DATASET 1: IRIS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Shape: {iris_df.shape}\")\n",
    "print(f\"Features: {list(iris.feature_names)}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(iris_df.head())\n",
    "\n",
    "# Dataset 2: Mall Customers (Creating synthetic data based on typical mall customer dataset)\n",
    "np.random.seed(42)\n",
    "n_customers = 200\n",
    "\n",
    "# Generate customer data\n",
    "customer_ids = range(1, n_customers + 1)\n",
    "genders = np.random.choice(['Male', 'Female'], n_customers)\n",
    "ages = np.random.randint(18, 70, n_customers)\n",
    "\n",
    "# Create distinct customer segments\n",
    "segment1 = np.random.normal(25, 5, 50)  # Young, low income\n",
    "segment2 = np.random.normal(55, 8, 50)  # Old, low income\n",
    "segment3 = np.random.normal(30, 7, 50)  # Young, high income\n",
    "segment4 = np.random.normal(45, 10, 50) # Middle-aged, high income\n",
    "\n",
    "annual_income = np.concatenate([segment1, segment2, segment3, segment4])\n",
    "spending_score = np.zeros(n_customers)\n",
    "\n",
    "# Spending based on income and age patterns\n",
    "for i in range(n_customers):\n",
    "    if annual_income[i] < 35 and ages[i] < 30:\n",
    "        spending_score[i] = np.random.randint(60, 100)  # Young, low income, high spending\n",
    "    elif annual_income[i] < 35 and ages[i] >= 30:\n",
    "        spending_score[i] = np.random.randint(1, 40)    # Old, low income, low spending\n",
    "    elif annual_income[i] >= 35 and ages[i] < 40:\n",
    "        spending_score[i] = np.random.randint(70, 100)  # Young, high income, high spending\n",
    "    else:\n",
    "        spending_score[i] = np.random.randint(40, 70)   # Middle-aged, moderate spending\n",
    "\n",
    "mall_df = pd.DataFrame({\n",
    "    'CustomerID': customer_ids,\n",
    "    'Gender': genders,\n",
    "    'Age': ages,\n",
    "    'Annual Income (k$)': annual_income,\n",
    "    'Spending Score (1-100)': spending_score\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"DATASET 2: MALL CUSTOMERS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Shape: {mall_df.shape}\")\n",
    "print(f\"Features: {list(mall_df.columns)}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(mall_df.head())\n",
    "\n",
    "# ============================================================================\n",
    "# PART 3: EXPLORATORY DATA ANALYSIS - IRIS DATASET\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"EDA: IRIS DATASET\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "print(iris_df.describe())\n",
    "\n",
    "# Missing values\n",
    "print(f\"\\nMissing Values:\\n{iris_df.isnull().sum()}\")\n",
    "\n",
    "# Correlation matrix\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Correlation heatmap\n",
    "iris_numeric = iris_df.drop(['species', 'species_name'], axis=1)\n",
    "sns.heatmap(iris_numeric.corr(), annot=True, cmap='coolwarm', center=0, ax=axes[0])\n",
    "axes[0].set_title('Iris: Feature Correlation Heatmap', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Distribution plots\n",
    "iris_df.drop(['species', 'species_name'], axis=1).boxplot(ax=axes[1])\n",
    "axes[1].set_title('Iris: Feature Distributions (Box Plot)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Value (cm)')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Pairplot for one feature\n",
    "sns.violinplot(data=iris_df, x='species_name', y='petal length (cm)', ax=axes[2])\n",
    "axes[2].set_title('Iris: Petal Length by Species', fontsize=14, fontweight='bold')\n",
    "axes[2].set_xlabel('Species')\n",
    "axes[2].set_ylabel('Petal Length (cm)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Outlier detection using Z-score\n",
    "z_scores = np.abs(zscore(iris_numeric))\n",
    "outliers = (z_scores > 3).sum(axis=0)\n",
    "print(f\"\\nOutliers (Z-score > 3):\")\n",
    "for col, count in zip(iris_numeric.columns, outliers):\n",
    "    print(f\"  {col}: {count}\")\n",
    "\n",
    "# Key findings\n",
    "print(\"\\nðŸ“Š KEY FINDINGS - IRIS:\")\n",
    "print(\"  â€¢ Strong correlation between petal length and petal width (0.96)\")\n",
    "print(\"  â€¢ Strong correlation between sepal length and petal length (0.87)\")\n",
    "print(\"  â€¢ Species show distinct petal measurements\")\n",
    "print(\"  â€¢ Minimal outliers detected\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 4: EXPLORATORY DATA ANALYSIS - MALL CUSTOMERS DATASET\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"EDA: MALL CUSTOMERS DATASET\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "print(mall_df.describe())\n",
    "\n",
    "# Missing values\n",
    "print(f\"\\nMissing Values:\\n{mall_df.isnull().sum()}\")\n",
    "\n",
    "# Visualizations\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Correlation heatmap\n",
    "mall_numeric = mall_df[['Age', 'Annual Income (k$)', 'Spending Score (1-100)']]\n",
    "sns.heatmap(mall_numeric.corr(), annot=True, cmap='coolwarm', center=0, ax=axes[0])\n",
    "axes[0].set_title('Mall: Feature Correlation Heatmap', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Age distribution by gender\n",
    "sns.histplot(data=mall_df, x='Age', hue='Gender', kde=True, ax=axes[1])\n",
    "axes[1].set_title('Mall: Age Distribution by Gender', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Age')\n",
    "\n",
    "# Income vs Spending scatter\n",
    "scatter = axes[2].scatter(mall_df['Annual Income (k$)'], \n",
    "                          mall_df['Spending Score (1-100)'],\n",
    "                          c=mall_df['Age'], cmap='viridis', alpha=0.6)\n",
    "axes[2].set_title('Mall: Income vs Spending Score', fontsize=14, fontweight='bold')\n",
    "axes[2].set_xlabel('Annual Income (k$)')\n",
    "axes[2].set_ylabel('Spending Score (1-100)')\n",
    "plt.colorbar(scatter, ax=axes[2], label='Age')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Outlier detection\n",
    "z_scores_mall = np.abs(zscore(mall_numeric))\n",
    "outliers_mall = (z_scores_mall > 3).sum(axis=0)\n",
    "print(f\"\\nOutliers (Z-score > 3):\")\n",
    "for col, count in zip(mall_numeric.columns, outliers_mall):\n",
    "    print(f\"  {col}: {count}\")\n",
    "\n",
    "# Key findings\n",
    "print(\"\\nðŸ“Š KEY FINDINGS - MALL CUSTOMERS:\")\n",
    "print(\"  â€¢ Age ranges from 18 to 70 years\")\n",
    "print(\"  â€¢ No strong linear correlations between features\")\n",
    "print(\"  â€¢ Multiple customer segments visible in income-spending plot\")\n",
    "print(\"  â€¢ Balanced gender distribution\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 5: DATA PREPROCESSING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"DATA PREPROCESSING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Prepare Iris data\n",
    "X_iris = iris_df.drop(['species', 'species_name'], axis=1)\n",
    "scaler_iris = StandardScaler()\n",
    "X_iris_scaled = scaler_iris.fit_transform(X_iris)\n",
    "\n",
    "print(\"âœ“ Iris data standardized\")\n",
    "print(f\"  Shape: {X_iris_scaled.shape}\")\n",
    "\n",
    "# Prepare Mall data\n",
    "X_mall = mall_df[['Age', 'Annual Income (k$)', 'Spending Score (1-100)']]\n",
    "scaler_mall = StandardScaler()\n",
    "X_mall_scaled = scaler_mall.fit_transform(X_mall)\n",
    "\n",
    "print(\"âœ“ Mall data standardized\")\n",
    "print(f\"  Shape: {X_mall_scaled.shape}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 6: K-MEANS CLUSTERING - ELBOW METHOD\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"K-MEANS: ELBOW METHOD\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "def plot_elbow_method(X, data_name, k_range=range(2, 11)):\n",
    "    \"\"\"Calculate and plot elbow method for optimal k\"\"\"\n",
    "    inertias = []\n",
    "    silhouette_scores = []\n",
    "    \n",
    "    for k in k_range:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        kmeans.fit(X)\n",
    "        inertias.append(kmeans.inertia_)\n",
    "        silhouette_scores.append(silhouette_score(X, kmeans.labels_))\n",
    "    \n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Elbow plot\n",
    "    axes[0].plot(k_range, inertias, 'bo-', linewidth=2, markersize=8)\n",
    "    axes[0].set_xlabel('Number of Clusters (k)', fontsize=12)\n",
    "    axes[0].set_ylabel('Inertia (Within-cluster sum of squares)', fontsize=12)\n",
    "    axes[0].set_title(f'{data_name}: Elbow Method', fontsize=14, fontweight='bold')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Silhouette plot\n",
    "    axes[1].plot(k_range, silhouette_scores, 'ro-', linewidth=2, markersize=8)\n",
    "    axes[1].set_xlabel('Number of Clusters (k)', fontsize=12)\n",
    "    axes[1].set_ylabel('Silhouette Score', fontsize=12)\n",
    "    axes[1].set_title(f'{data_name}: Silhouette Score by k', fontsize=14, fontweight='bold')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Find optimal k\n",
    "    optimal_k_silhouette = k_range[np.argmax(silhouette_scores)]\n",
    "    print(f\"\\n{data_name} - Optimal k (Silhouette): {optimal_k_silhouette}\")\n",
    "    print(f\"Max Silhouette Score: {max(silhouette_scores):.4f}\")\n",
    "    \n",
    "    return optimal_k_silhouette\n",
    "\n",
    "# Apply to both datasets\n",
    "optimal_k_iris = plot_elbow_method(X_iris_scaled, \"IRIS\")\n",
    "optimal_k_mall = plot_elbow_method(X_mall_scaled, \"MALL CUSTOMERS\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 7: K-MEANS CLUSTERING - FINAL MODELS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"K-MEANS: FINAL CLUSTERING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Iris K-Means\n",
    "kmeans_iris = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "iris_df['kmeans_cluster'] = kmeans_iris.fit_predict(X_iris_scaled)\n",
    "\n",
    "print(\"\\nIRIS K-MEANS (k=3):\")\n",
    "print(f\"  Inertia: {kmeans_iris.inertia_:.4f}\")\n",
    "print(f\"  Silhouette Score: {silhouette_score(X_iris_scaled, iris_df['kmeans_cluster']):.4f}\")\n",
    "print(f\"  Davies-Bouldin Index: {davies_bouldin_score(X_iris_scaled, iris_df['kmeans_cluster']):.4f}\")\n",
    "print(f\"  Calinski-Harabasz Score: {calinski_harabasz_score(X_iris_scaled, iris_df['kmeans_cluster']):.4f}\")\n",
    "\n",
    "# Mall K-Means\n",
    "kmeans_mall = KMeans(n_clusters=5, random_state=42, n_init=10)\n",
    "mall_df['kmeans_cluster'] = kmeans_mall.fit_predict(X_mall_scaled)\n",
    "\n",
    "print(\"\\nMALL CUSTOMERS K-MEANS (k=5):\")\n",
    "print(f\"  Inertia: {kmeans_mall.inertia_:.4f}\")\n",
    "print(f\"  Silhouette Score: {silhouette_score(X_mall_scaled, mall_df['kmeans_cluster']):.4f}\")\n",
    "print(f\"  Davies-Bouldin Index: {davies_bouldin_score(X_mall_scaled, mall_df['kmeans_cluster']):.4f}\")\n",
    "print(f\"  Calinski-Harabasz Score: {calinski_harabasz_score(X_mall_scaled, mall_df['kmeans_cluster']):.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 8: HIERARCHICAL CLUSTERING - DENDROGRAMS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"HIERARCHICAL CLUSTERING: DENDROGRAMS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "linkage_methods = ['single', 'complete', 'average']\n",
    "\n",
    "# Iris dendrograms\n",
    "for idx, method in enumerate(linkage_methods):\n",
    "    Z = linkage(X_iris_scaled, method=method)\n",
    "    dendrogram(Z, ax=axes[0, idx], truncate_mode='lastp', p=12, leaf_font_size=10)\n",
    "    axes[0, idx].set_title(f'Iris: {method.capitalize()} Linkage', fontsize=12, fontweight='bold')\n",
    "    axes[0, idx].set_xlabel('Sample Index or (Cluster Size)')\n",
    "    axes[0, idx].set_ylabel('Distance')\n",
    "\n",
    "# Mall dendrograms\n",
    "for idx, method in enumerate(linkage_methods):\n",
    "    Z = linkage(X_mall_scaled, method=method)\n",
    "    dendrogram(Z, ax=axes[1, idx], truncate_mode='lastp', p=12, leaf_font_size=10)\n",
    "    axes[1, idx].set_title(f'Mall: {method.capitalize()} Linkage', fontsize=12, fontweight='bold')\n",
    "    axes[1, idx].set_xlabel('Sample Index or (Cluster Size)')\n",
    "    axes[1, idx].set_ylabel('Distance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Dendrograms generated for both datasets with 3 linkage methods\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 9: HIERARCHICAL CLUSTERING - FINAL MODELS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"HIERARCHICAL CLUSTERING: FINAL MODELS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Test different linkage methods\n",
    "linkage_comparison = []\n",
    "\n",
    "for method in ['single', 'complete', 'average', 'ward']:\n",
    "    # Iris\n",
    "    hc_iris = AgglomerativeClustering(n_clusters=3, linkage=method)\n",
    "    iris_labels = hc_iris.fit_predict(X_iris_scaled)\n",
    "    iris_sil = silhouette_score(X_iris_scaled, iris_labels)\n",
    "    \n",
    "    # Mall\n",
    "    hc_mall = AgglomerativeClustering(n_clusters=5, linkage=method)\n",
    "    mall_labels = hc_mall.fit_predict(X_mall_scaled)\n",
    "    mall_sil = silhouette_score(X_mall_scaled, mall_labels)\n",
    "    \n",
    "    linkage_comparison.append({\n",
    "        'Linkage': method,\n",
    "        'Iris Silhouette': iris_sil,\n",
    "        'Mall Silhouette': mall_sil\n",
    "    })\n",
    "\n",
    "linkage_df = pd.DataFrame(linkage_comparison)\n",
    "print(\"\\nLinkage Method Comparison:\")\n",
    "print(linkage_df.to_string(index=False))\n",
    "\n",
    "# Select best linkage (average for Iris, ward for Mall based on typical performance)\n",
    "best_linkage_iris = 'average'\n",
    "best_linkage_mall = 'ward'\n",
    "\n",
    "# Final hierarchical models\n",
    "hc_iris = AgglomerativeClustering(n_clusters=3, linkage=best_linkage_iris)\n",
    "iris_df['hierarchical_cluster'] = hc_iris.fit_predict(X_iris_scaled)\n",
    "\n",
    "hc_mall = AgglomerativeClustering(n_clusters=5, linkage=best_linkage_mall)\n",
    "mall_df['hierarchical_cluster'] = hc_mall.fit_predict(X_mall_scaled)\n",
    "\n",
    "print(f\"\\nâœ“ Final Models Created:\")\n",
    "print(f\"  Iris: {best_linkage_iris} linkage, 3 clusters\")\n",
    "print(f\"  Mall: {best_linkage_mall} linkage, 5 clusters\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 10: CLUSTER VISUALIZATION - PCA\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CLUSTER VISUALIZATION: PCA\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# PCA for Iris\n",
    "pca_iris = PCA(n_components=2)\n",
    "X_iris_pca = pca_iris.fit_transform(X_iris_scaled)\n",
    "\n",
    "# PCA for Mall\n",
    "pca_mall = PCA(n_components=2)\n",
    "X_mall_pca = pca_mall.fit_transform(X_mall_scaled)\n",
    "\n",
    "# Plotting\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Iris - Actual Species\n",
    "scatter = axes[0, 0].scatter(X_iris_pca[:, 0], X_iris_pca[:, 1], \n",
    "                             c=iris_df['species'], cmap='viridis', s=50, alpha=0.6)\n",
    "axes[0, 0].set_title('Iris: Actual Species', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel(f'PC1 ({pca_iris.explained_variance_ratio_[0]:.2%} variance)')\n",
    "axes[0, 0].set_ylabel(f'PC2 ({pca_iris.explained_variance_ratio_[1]:.2%} variance)')\n",
    "plt.colorbar(scatter, ax=axes[0, 0])\n",
    "\n",
    "# Iris - K-Means\n",
    "scatter = axes[0, 1].scatter(X_iris_pca[:, 0], X_iris_pca[:, 1], \n",
    "                             c=iris_df['kmeans_cluster'], cmap='viridis', s=50, alpha=0.6)\n",
    "axes[0, 1].set_title('Iris: K-Means Clusters', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_xlabel(f'PC1 ({pca_iris.explained_variance_ratio_[0]:.2%} variance)')\n",
    "axes[0, 1].set_ylabel(f'PC2 ({pca_iris.explained_variance_ratio_[1]:.2%} variance)')\n",
    "plt.colorbar(scatter, ax=axes[0, 1])\n",
    "\n",
    "# Iris - Hierarchical\n",
    "scatter = axes[0, 2].scatter(X_iris_pca[:, 0], X_iris_pca[:, 1], \n",
    "                             c=iris_df['hierarchical_cluster'], cmap='viridis', s=50, alpha=0.6)\n",
    "axes[0, 2].set_title('Iris: Hierarchical Clusters', fontsize=12, fontweight='bold')\n",
    "axes[0, 2].set_xlabel(f'PC1 ({pca_iris.explained_variance_ratio_[0]:.2%} variance)')\n",
    "axes[0, 2].set_ylabel(f'PC2 ({pca_iris.explained_variance_ratio_[1]:.2%} variance)')\n",
    "plt.colorbar(scatter, ax=axes[0, 2])\n",
    "\n",
    "# Mall - Original features\n",
    "scatter = axes[1, 0].scatter(mall_df['Annual Income (k$)'], \n",
    "                             mall_df['Spending Score (1-100)'],\n",
    "                             c=mall_df['Age'], cmap='viridis', s=50, alpha=0.6)\n",
    "axes[1, 0].set_title('Mall: Income vs Spending (by Age)', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Annual Income (k$)')\n",
    "axes[1, 0].set_ylabel('Spending Score (1-100)')\n",
    "plt.colorbar(scatter, ax=axes[1, 0], label='Age')\n",
    "\n",
    "# Mall - K-Means\n",
    "scatter = axes[1, 1].scatter(mall_df['Annual Income (k$)'], \n",
    "                             mall_df['Spending Score (1-100)'],\n",
    "                             c=mall_df['kmeans_cluster'], cmap='viridis', s=50, alpha=0.6)\n",
    "axes[1, 1].set_title('Mall: K-Means Clusters', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Annual Income (k$)')\n",
    "axes[1, 1].set_ylabel('Spending Score (1-100)')\n",
    "plt.colorbar(scatter, ax=axes[1, 1])\n",
    "\n",
    "# Mall - Hierarchical\n",
    "scatter = axes[1, 2].scatter(mall_df['Annual Income (k$)'], \n",
    "                             mall_df['Spending Score (1-100)'],\n",
    "                             c=mall_df['hierarchical_cluster'], cmap='viridis', s=50, alpha=0.6)\n",
    "axes[1, 2].set_title('Mall: Hierarchical Clusters', fontsize=12, fontweight='bold')\n",
    "axes[1, 2].set_xlabel('Annual Income (k$)')\n",
    "axes[1, 2].set_ylabel('Spending Score (1-100)')\n",
    "plt.colorbar(scatter, ax=axes[1, 2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"âœ“ Iris PCA - Explained Variance: {pca_iris.explained_variance_ratio_.sum():.2%}\")\n",
    "print(f\"âœ“ Mall PCA - Explained Variance: {pca_mall.explained_variance_ratio_.sum():.2%}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 11: QUANTITATIVE COMPARISON\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"QUANTITATIVE COMPARISON OF CLUSTERING ALGORITHMS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Calculate metrics for all combinations\n",
    "metrics_data = []\n",
    "\n",
    "# Iris - K-Means\n",
    "metrics_data.append({\n",
    "    'Dataset': 'Iris',\n",
    "    'Algorithm': 'K-Means',\n",
    "    'Silhouette Score': silhouette_score(X_iris_scaled, iris_df['kmeans_cluster']),\n",
    "    'Davies-Bouldin Index': davies_bouldin_score(X_iris_scaled, iris_df['kmeans_cluster']),\n",
    "    'Calinski-Harabasz Score': calinski_harabasz_score(X_iris_scaled, iris_df['kmeans_cluster'])\n",
    "})\n",
    "\n",
    "# Iris - Hierarchical\n",
    "metrics_data.append({\n",
    "    'Dataset': 'Iris',\n",
    "    'Algorithm': 'Hierarchical',\n",
    "    'Silhouette Score': silhouette_score(X_iris_scaled, iris_df['hierarchical_cluster']),\n",
    "    'Davies-Bouldin Index': davies_bouldin_score(X_iris_scaled, iris_df['hierarchical_cluster']),\n",
    "    'Calinski-Harabasz Score': calinski_harabasz_score(X_iris_scaled, iris_df['hierarchical_cluster'])\n",
    "})\n",
    "\n",
    "# Mall - K-Means\n",
    "metrics_data.append({\n",
    "    'Dataset': 'Mall',\n",
    "    'Algorithm': 'K-Means',\n",
    "    'Silhouette Score': silhouette_score(X_mall_scaled, mall_df['kmeans_cluster']),\n",
    "    'Davies-Bouldin Index': davies_bouldin_score(X_mall_scaled, mall_df['kmeans_cluster']),\n",
    "    'Calinski-Harabasz Score': calinski_harabasz_score(X_mall_scaled, mall_df['kmeans_cluster'])\n",
    "})\n",
    "\n",
    "# Mall - Hierarchical\n",
    "metrics_data.append({\n",
    "    'Dataset': 'Mall',\n",
    "    'Algorithm': 'Hierarchical',\n",
    "    'Silhouette Score': silhouette_score(X_mall_scaled, mall_df['hierarchical_cluster']),\n",
    "    'Davies-Bouldin Index': davies_bouldin_score(X_mall_scaled, mall_df['hierarchical_cluster']),\n",
    "    'Calinski-Harabasz Score': calinski_harabasz_score(X_mall_scaled, mall_df['hierarchical_cluster'])\n",
    "})\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_data)\n",
    "print(\"\\nClustering Performance Metrics:\")\n",
    "print(metrics_df.to_string(index=False))\n",
    "\n",
    "print(\"\\nðŸ“Š Metric Interpretation:\")\n",
    "print(\"  â€¢ Silhouette Score: Higher is better (range: -1 to 1)\")\n",
    "print(\"  â€¢ Davies-Bouldin Index: Lower is better (minimum: 0)\")\n",
    "print(\"  â€¢ Calinski-Harabasz Score: Higher is better\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 12: CLUSTER INTERPRETATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CLUSTER INTERPRETATION AND INSIGHTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Iris cluster analysis\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"IRIS DATASET - K-MEANS CLUSTERS\")\n",
    "print(\"=\"*50)\n",
    "iris_cluster_summary = iris_df.groupby('kmeans_cluster')[\n",
    "    ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
    "].mean()\n",
    "print(iris_cluster_summary)\n",
    "\n",
    "print(\"\\nCluster Sizes:\")\n",
    "print(iris_df['kmeans_cluster'].value_counts().sort_index())\n",
    "\n",
    "# Mall cluster analysis\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MALL CUSTOMERS - K-MEANS CLUSTERS\")\n",
    "print(\"=\"*50)\n",
    "mall_cluster_summary = mall_df.groupby('kmeans_cluster')[\n",
    "    ['Age', 'Annual Income (k$)', 'Spending Score (1-100)']\n",
    "].mean()\n",
    "print(mall_cluster_summary)\n",
    "\n",
    "print(\"\\nCluster Sizes:\")\n",
    "print(mall_df['kmeans_cluster'].value_counts().sort_index())\n",
    "\n",
    "# Segment naming for Mall clusters\n",
    "print(\"\\nðŸŽ¯ CUSTOMER SEGMENT PROFILES:\")\n",
    "for cluster_id in sorted(mall_df['kmeans_cluster'].unique()):\n",
    "    cluster_data = mall_df[mall_df['kmeans_cluster'] == cluster_id]\n",
    "    avg_age = cluster_data['Age'].mean()\n",
    "    avg_income = cluster_data['Annual Income (k$)'].mean()\n",
    "    avg_spending = cluster_data['Spending Score (1-100)'].mean()\n",
    "    size = len(cluster_data)\n",
    "    \n",
    "    # Segment naming logic\n",
    "    if avg_income < 35 and avg_spending > 60:\n",
    "        segment_name = \"Budget Enthusiasts\"\n",
    "    elif avg_income < 35 and avg_spending < 40:\n",
    "        segment_name = \"Careful Spenders\"\n",
    "    elif avg_income >= 35 and avg_spending > 60:\n",
    "        segment_name = \"Premium Customers\"\n",
    "    elif avg_income >= 35 and avg_spending < 50:\n",
    "        segment_name = \"High Income Conservatives\"\n",
    "    else:\n",
    "        segment_name = \"Moderate Spenders\"\n",
    "    \n",
    "    print(f\"\\nCluster {cluster_id}: {segment_name}\")\n",
    "    print(f\"  Size: {size} customers ({size/len(mall_df)*100:.1f}%)\")\n",
    "    print(f\"  Avg Age: {avg_age:.1f} years\")\n",
    "    print(f\"  Avg Income: ${avg_income:.1f}k\")\n",
    "    print(f\"  Avg Spending Score: {avg_spending:.1f}/100\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 13: PARAMETER SENSITIVITY ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PARAMETER SENSITIVITY ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Test different k values for K-Means\n",
    "k_values = range(2, 9)\n",
    "sensitivity_results = []\n",
    "\n",
    "for k in k_values:\n",
    "    # Iris\n",
    "    kmeans_iris_temp = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels_iris = kmeans_iris_temp.fit_predict(X_iris_scaled)\n",
    "    \n",
    "    # Mall\n",
    "    kmeans_mall_temp = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels_mall = kmeans_mall_temp.fit_predict(X_mall_scaled)\n",
    "    \n",
    "    sensitivity_results.append({\n",
    "        'k': k,\n",
    "        'Iris Silhouette': silhouette_score(X_iris_scaled, labels_iris),\n",
    "        'Mall Silhouette': silhouette_score(X_mall_scaled, labels_mall)\n",
    "    })\n",
    "\n",
    "sensitivity_df = pd.DataFrame(sensitivity_results)\n",
    "\n",
    "# Plot sensitivity analysis\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "ax.plot(sensitivity_df['k'], sensitivity_df['Iris Silhouette'], 'o-', label='Iris', linewidth=2, markersize=8)\n",
    "ax.plot(sensitivity_df['k'], sensitivity_df['Mall Silhouette'], 's-', label='Mall Customers', linewidth=2, markersize=8)\n",
    "ax.set_xlabel('Number of Clusters (k)', fontsize=12)\n",
    "ax.set_ylabel('Silhouette Score', fontsize=12)\n",
    "ax.set_title('K-Means Parameter Sensitivity Analysis', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSensitivity Analysis Results:\")\n",
    "print(sensitivity_df.to_string(index=False))\n",
    "\n",
    "# ============================================================================\n",
    "# PART 14: FINAL COMPARISON AND RECOMMENDATIONS\n",
    "# ============"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
